\providecommand{\base}{../..}
\providecommand{\ifallthenelse}[2]{#2}
\documentclass[10pt,a4paper,notitlepage]{article}
\RequirePackage[l2tabu, orthodox]{nag}
\usepackage[utf8]{inputenc}
\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{qtree}
\usepackage{amssymb}
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{braket}
\usepackage{stmaryrd}

\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{refcount}
\usepackage{subfiles}
\usepackage{microtype}
\usepackage{mathtools}
\usepackage{listings}

\usepackage[autostyle]{csquotes}
\usepackage{marvosym}
\usepackage{xparse}
\usepackage{expl3}
\usepackage{l3str}
\usepackage{xpatch}
\usepackage{tikzsymbols}
\hypersetup{
	colorlinks,
	citecolor=black,
	filecolor=black,
	linkcolor=black,
	urlcolor=black,
	bookmarks=true,
	linktocpage=true,
	hyperindex=true,
	bookmarks=true
}

\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}
\theoremstyle{definition}
\newtheorem{defn}[thm]{\protect\definitionname}
\theoremstyle{definition}
\newtheorem{example}[thm]{\protect\examplename}
\theoremstyle{remark}
\newtheorem{application}[thm]{\protect\applicationname}
\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\theoremstyle{plain}
\newtheorem{prop}[thm]{\protect\propositionname}
\theoremstyle{plain}
\newtheorem{cor}[thm]{\protect\corollaryname}
\theoremstyle{remark}
\newtheorem{claim}[thm]{\protect\claimname}

\addto\captionsenglish{\renewcommand{\claimname}{Claim}}
\addto\captionsenglish{\renewcommand{\corollaryname}{Corollary}}
\addto\captionsenglish{\renewcommand{\definitionname}{Definition}}
\addto\captionsenglish{\renewcommand{\examplename}{Example}}
\addto\captionsenglish{\renewcommand{\applicationname}{Application}}
\addto\captionsenglish{\renewcommand{\lemmaname}{Lemma}}
\addto\captionsenglish{\renewcommand{\lstlistingname}{Listing}}
\addto\captionsenglish{\renewcommand{\propositionname}{Proposition}}
\addto\captionsenglish{\renewcommand{\remarkname}{Remark}}
\addto\captionsenglish{\renewcommand{\theoremname}{Theorem}}

\addto\captionsfrench{\renewcommand{\claimname}{Affirmation}}
\addto\captionsfrench{\renewcommand{\corollaryname}{Corollaire}}
\addto\captionsfrench{\renewcommand{\definitionname}{Définition}}
\addto\captionsfrench{\renewcommand{\examplename}{Exemple}}
\addto\captionsfrench{\renewcommand{\applicationname}{Application}}
\addto\captionsfrench{\renewcommand{\lemmaname}{Lemme}}
\addto\captionsfrench{\renewcommand{\lstlistingname}{Listing}}
\addto\captionsfrench{\renewcommand{\propositionname}{Proposition}}
\addto\captionsfrench{\renewcommand{\remarkname}{Remarque}}
\addto\captionsfrench{\renewcommand{\theoremname}{Théorème}}

\providecommand{\claimname}{Affirmation}
\providecommand{\corollaryname}{Corollaire}
\providecommand{\definitionname}{Définition}
\providecommand{\examplename}{Exemple}
\providecommand{\applicationname}{Application}
\providecommand{\lemmaname}{Lemme}
\providecommand{\propositionname}{Proposition}
\providecommand{\remarkname}{Remarque}
\providecommand{\theoremname}{Théorème}
\renewcommand{\lstlistingname}{Listing}

\begin{document}
	
%\usepackage{thmbox}
%\usepackage[framemethod=tikz]{mdframed}





\title{Mémoire\\Langages algébriques. Exemples et applications.}
\author{Xavier \textsc{Montillet}}
\maketitle
\begin{abstract}
Les langages algébriques sont assez complexes pour pouvoir représenter la plupart des langages de programmations actuels tout en étant assez simples pour que certaines propriétés restent décidables. Ils ont de nombreuses applications en compilation.

Dans cette leçon, nous présentons d'abord les représentations usuelles des langages algébriques et quelques-unes de leurs propriétés. Nous nous intéressons ensuite aux problèmes de décision sur les langages algébriques.

Enfin, nous décrivons leurs applications à la compilation et certaines sous-classes utiles dans ce cadre.
\end{abstract}
\setcounter{tocdepth}{3}
\tableofcontents
\newpage
\renewcommand\thesection{\arabic{section}}

\global\long\def\leftbrace#1{\left\{  #1\right.}


\global\long\def\L{\mathcal{L}}

\global\long\def\A{\mathcal{A}}


\global\long\def\N{\mathbb{N}}


\global\long\def\abs#1{\left|#1\right|}


\global\long\def\transitionn#1#2{\overset{#1{\color{white}#2}}{\leadsto^{#2}}}

\global\long\def\L{\mathcal{L}}


\global\long\def\It{\operatorname{It}}


\global\long\def\transition#1{\overset{#1}{\leadsto}}


\global\long\def\hist#1{\operatorname{hist}\left(#1\right)}


\global\long\def\intint#1#2{\left\llbracket #1,\ #2\right\rrbracket }


\section{Représentations}

Dans cette section, nous donnons deux définitions équivalentes des langages algébriques : une par des grammaires et une par des automates.

\subsection{Grammaires algébriques}

%\subsubsection{Définition et premières propriétés} % {[}Carton, p. 75-79{]}

\begin{defn}[Grammaire algébrique]
	Une \emph{grammaire algébrique} est un quadruplet $(\Sigma, V, R, S)$ où $\Sigma$ et $V$ sont des ensembles finis disjoints, $R\subseteq V\times(V\sqcup\Sigma)^*$ et $S\in V$. Les éléments de $\Sigma$ sont appelés \emph{terminaux} et ceux de $V$ sont appelés \emph{variables} ou \emph{non terminaux}. Les éléments de $R$ sont appelés \emph{règles}. Le non terminal $S$ est appelé \emph{axiome}. On note $X\to u_1+\dots+u_n$ pour $(X,u_1),\dots,(X_,u_n)\in R$.
\end{defn}

\begin{example}
	$G_{1}=\left(\Sigma_{1},\ V_{1},\ R_{1}\right)$, $\Sigma_{1}=\set{a,\ b}$,
	$V_{1}=\set S$, $R_{1}=\set{S\to aSb,\ S\to\varepsilon}$
\end{example}

\begin{rem}
	On se contentera souvent de donner $R$ en utilisant la convention
	que les lettres minuscules sont des symboles terminaux et que les
	lettres majuscules sont des symboles non terminaux.
\end{rem}

\begin{example}
	$G_{1}=\left\{ S\to aSb+\varepsilon\right\} $, $G_{2}=\left\{ \begin{array}{c}
	P\to aI+\varepsilon\\
	I\to aP
	\end{array}\right\} $
	$$G_{3,n}=\left\{ \begin{array}{c}
	S\to ST+\varepsilon\\
	T\to a_{1}Sb_{1}S\ +\ \dots\ +\ a_{n}Sb_{n}S\ +\ \varepsilon
	\end{array}\right\} $$
\end{example}

\begin{defn}[Dérivation]
	On étend $\to$ à $(V\sqcup\Sigma)^*$ par $\alpha X \beta \to \alpha u \beta$ si $X\to u$. On note $\to^*$ la clôture réflexive transitive de $\to$. Si $u\to v$, on dit que $u$ se \emph{dérive directement} en $v$.
\end{defn}

\begin{example}
	$S\to aSb\to aaSbb\to aabb$ dans $G_{1}$
\end{example}

\begin{defn}[Langage engendré]
	Pour tout $X\in V$, on pose $\widehat{\L_{G}}\left(u\right)\coloneqq \set{v\in (V\sqcup\Sigma)^*:u\to^* v}$ et $\L_{G}\left(u\right)\coloneqq \widehat{\L_{G}}\left(u\right)\cap \Sigma^*$. On appelle $\L_{G}\left(u\right)$ \emph{langage engendré} par $u$ dans $G$. On appelle \emph{langage engendré} par la grammaire et note $\L\left(G\right)$ le langage $\L_{G}\left(S\right)$ engendré par l'axiom.
\end{defn}

\begin{example}
	$\L_{G_{1}}\left(S\right)=\set{a^{n}b^{n}\ |\ n\in\N}$, $\L_{G_{2}}\left(P\right)=\set{a^{2n}\ |\ n\in\N}$,
	$\L_{G_{2}}\left(I\right)=\set{a^{2n+1}\ |\ n\in\N}$, $D_{n}^{*}\coloneqq\L_{G_{3,n}}\left(S\right)$
	est appelé \emph{langage de Dyck}\label{dyck}. C'est le langage des mots bien parenthésés
	(si l'on considère $a_{i}$ comme une parenthèse ouvrante et $b_{i}$
	comme la parenthèse fermante correspondante).
\end{example}

\begin{defn}[Langage algébrique]
	Un \emph{langage algébrique} est un langage engendré par une grammaire algébrique.
\end{defn}

\begin{lem}[Fondamental]
	Soit $G=(\Sigma,V,R,S)$ une grammaire algébrique et $u$ et $v$ deux mots de $(V\sqcup \Sigma)^*$. On suppose que $u$ se factorise $u=u_1u_2$. Alors il existe une dérivation $u\to^k v$ de longueur $k$ si et seulement si $v$ se factorise $v=v_1v_2$ et s'il existe deux dérivations $u_1\to^{k_1}v_1$ et $u_2\to^{k_2}v_2$ où $k=k_1+k_2$.
\end{lem}



%\subsubsection{Simplifications des grammaires} %{[}Carton, p.79-82{]}

\begin{defn}[Grammaire réduite]
	Une grammaire $G=(\Sigma,V,R,S)$ est dite \emph{réduite} si
	\begin{itemize}
		\item pour tout $X\in V$, $\L_G(X)\not=\emptyset$,
		\item pour tout $X\in V$, il existe $u,v\in(\Sigma\sqcup V)^*$ tels que $S\to^*uXv$.
	\end{itemize}
\end{defn}

\begin{prop}[Grammaire réduite]
	Pour toute grammaire algébrique $G$, $\L_{G}$ est engendré par une grammaire réduite de taille $O\left(\abs G\right)$
	calculable en temps $O\left(\abs G\right)$.
\end{prop}

\begin{defn}[Grammaire propre]
	Une grammaire $G=(\Sigma,V,R,S)$ est dite \emph{propre} si elle ne contient aucune règle de la forme $X\to \varepsilon$ ou de la forme $X\to Y$ pour $X,Y\in V$.
\end{defn}

\begin{prop}[Grammaire propre]
	Pour toute grammaire algébrique $G$, $\L_{G}\setminus\set{\varepsilon}$ est engendré par une grammaire
	propre de taille $O\left(\abs G^{2}\right)$ calculable en temps $O\left(\abs G^{2}\right)$.
\end{prop}

\begin{defn}[Forme normale quadratique / de Chomsky]
	Une grammaire $G=(\Sigma,V,R,S)$ est dite en \emph{forme normale quadratique} si toutes ses règles sont de la forme $X\to YZ$ ou $X\to a$ où $X,Y,Z\in V$ et $a\in\Sigma$.
\end{defn}

\begin{prop}[Forme normale quadratique / de Chomsky]
	Pour toute grammaire algébrique $G$, $\L_{G}\setminus\set{\varepsilon}$ est engendré par une grammaire
	en forme normale quadratique de taille $O\left(\abs G^{2}\right)$
	calculable en temps $O\left(\abs G^{2}\right)$.
\end{prop}

%\begin{defn}
%	(Forme normale de Greibach) {[}Carton, p. 102{]}\end{defn}
%{[}Hopcroft, p. 295{]} \{Tout est
% dans le Carton sauf les complexités\}
%\begin{prop}
%		\item $\L_{G}\setminus\set{\varepsilon}$ est engendré par une grammaire
%		en forme normale de Greibach (quadratique).
%	\end{itemize}
%\end{prop}

\subsection{Automates à pile} % {[}Carton, p. 104-109; 112{]}



\begin{defn}[Automate à pile]
	Un \emph{automate à pile} est un septuplet $\A=(Q,\Sigma, \Gamma, \Delta, q_0, \gamma_0, F)$ où $Q$ est un ensemble fini d'états, $\Sigma$ est l'\emph{alphabet d'entrée}, $\Gamma$ est l'\emph{alphabet de pile}, $\Delta\subseteq\left(Q\times (\Sigma\sqcup \{\varepsilon\})\times (\Gamma \sqcup \{\varepsilon\})\right)\times\left( Q\times \Gamma^*\right)$ décrit les transitions, $q_0$ est l'\emph{état initial}, $\gamma_0$ est le \emph{symbole de pile initial} et $F\subseteq Q\times\Gamma^*$ est l'ensemble des \emph{configurations acceptantes} (qui sont d'une forme particulière décrite plus bas). On note $(q, \gamma)\overset{u}{\rightarrowtail} (q', \alpha)$ pour $((q,u,\gamma),(q',\alpha))\in \Delta$.
\end{defn}

\begin{defn}[Calcul d'un automate à pile]
	On appelle \emph{configuration} un élément de $Q\times\Gamma^*$. Une \emph{étape de calcul} est une paire de configurations $(C,C')$ telles que $C=(q,\gamma\beta)$, $C'=(q',\alpha\beta)$ et $(q, \gamma)\overset{u}{\rightarrowtail} (q', \alpha)$. On la note $C\transition{u}C'$. Un \emph{calcul} est une suite d'étapes de calcul consécutives $C_0\transition{u_1}C_1\transition{u_2}\dots \transition{u_n}C_n$. Le mot $u_1\dots u_n$ est l'\emph{étiquette} du calcul.
\end{defn}

\begin{defn}[Modes d'acceptation d'un automate à pile]
	Il existe plusieurs \emph{modes d'acceptation} pour définir $F$.
	\begin{itemize}
		\item Pile vide : $(q,\alpha)\in F \iff \alpha = \varepsilon$.
		\item État final : $(q,\alpha)\in F \iff q\in Q_F$ où $Q_F\subseteq Q$ est un ensemble d'états dits finaux.
	\end{itemize}
\end{defn}

\begin{defn}[Langage accepté]
	Un mot $u$ est \emph{accepté} par un automate $\A$ à pile s'il existe un calcul $(q_0,\gamma_0)\transitionn{u}{*}C$ de la configuration initiale $(q_0,\gamma_0)$ à une configuration finale $C\in F$. Le langage $\L(\A)$ \emph{accepté} par un automate $\A$ est l'ensemble des mots qu'il accepte.
\end{defn}

\begin{prop}[Équivalence des modes d'acceptation]
	Les différents modes d'acceptation sont équivalents dans la mesure où ils permettent tous d'accepter exactement les mêmes langages.	
\end{prop}

\begin{thm}[Équivalence grammaires algébriques / automates à piles]\label{th:equiv}
	Un langage $L\subseteq\Sigma^*$ est engendré par une grammaire algébrique si et seulement si il est accepté par un automate à pile.	
\end{thm}

\section{Propriétés}

\subsection{Lemme d'itération} % {[}Carton, p. 92-95{]}

Dans cette sous-section, nous nous intéressons à l'équivalent du lemme de l'étoile pour les langages algébriques : le lemme d'Ogden. Il permet, entre autres, de démontrer que certains langages ne sont pas algébriques.

\begin{lem}[Ogden]\label{th:ogden}
	Pour tout grammaire $G=(\Sigma,V,R,S)$ et toute variable $X\in V$, il existe un entier $K$ tel que tout mot $f\in \widehat{\L_G(X)}$ ayant au moins $K$ lettres distinguées se factorise en $f=\alpha u \beta v \gamma$, où $\alpha,u,\beta,v,\gamma\in (\Sigma\sqcup V)^*$, avec
	\begin{itemize}
		\item $S\to^*\alpha T \gamma$ et $T\to ^*uTv+\beta$
		\item soit $\alpha, u, \beta$, soit $\beta, v, \gamma$ conteinnent des lettres distinguées.
		\item $u\beta v$ contient moins de $K$ lettres distinguées.
	\end{itemize}
\end{lem}

\begin{cor}[Théorème de Bar-Hillel, Perles et Shamir]\label{th:bhs}
	Pour tout langage algébrique $L$, il existe $N\ge 0$ tel que pour tout mot $f\in L$, si $\abs{f}\ge N$ alors on peut trouver une factorisation $f=\alpha u \beta v \gamma$ telle que $\abs{uv}>0$, $\abs{u\beta v}<N$ et $\alpha u^n \beta v^n \gamma\in L$ pour tout $n\ge 0$.	
\end{cor}

\begin{application}[de \ref{th:bhs}]
	Le langage $\set{a^{n}b^{n}c^{n}\ |\ n\in\N}$ n'est pas algébrique.
\end{application}

\begin{example}
	Ce langage pourrait représenter de la mise en forme en mode texte. \begin{lstlisting}
	+-------+
	| titre |
	+-------+
	\end{lstlisting}
\end{example}

\begin{application}[de \ref{th:ogden}]
	Le langage $\set{a^{m}b^{n}c^{m}d^{n}\ |\ n,m\in\N}$ n'est pas algébrique.
	
	Ce langage pourrait représenter le fait qu'on a déclaré deux procédures
	à $m$ et $n$ arguments et qu'on les a ensuite utilisées. % {[}Dragon,p. 179{]}
\end{application}

\subsection{Propriétés de clôture}

Dans cette sous-section, nous nous intéressons aux propriétés de clôture des langages algébriques qui permettent de construire des langages algébriques à partir d'autres langages algébriques (a priori plus simples).

\begin{prop}[Opérations rationnelles]
	L'ensemble des langages algébrique est clos par union, concaténation et étoile.
\end{prop}

\begin{prop}
	Tout langage rationnel est algébrique et l'inclusion est stricte.
\end{prop}

\begin{prop}
	L'ensemble des langages algébrique est clos par intersection avec un rationnel mais ni par complémentation, ni par intersection.
\end{prop}

\begin{defn}[Morphisme]
	Un \emph{morphisme} de $X^*$ dans $Y^*$ est une fonction $\varphi:X^*\to Y^*$ telle que $\varphi(\varepsilon) = \varepsilon$ et $\varphi(uv)=\varphi(u)\varphi(v)$ pour tous $u,v\in X ^*$. L'\emph{image} de $L\subseteq X^*$ par $\varphi$ est $\set{f(u) : u \in L}$ et l'\emph{image inverse} de $L'\subseteq Y^*$ par $\varphi$ est $\set{u \in X^* : \varphi(u) \in L'}$.
\end{defn}

\begin{prop}
	L'ensemble des langages algébrique est clos par morphisme et morphisme inverse.
\end{prop}

\begin{defn}[Substitution algébrique]
	Une \emph{substitution algébrique} est une fonction $\sigma:X^*\to \mathcal{P}(Y^*)$ telle que $\sigma(\varepsilon)=\set{\varepsilon}$, $\sigma(uv)=\sigma(u)\sigma(v)$ pour tous $u,v\in X ^*$, et pour tout $a\in X$, $\sigma(a)$ est algébrique. L'\emph{image} de $L\subseteq X^*$ par $\sigma$ est $\underset{u\in L}{\bigcup}\sigma(u)$.
\end{defn}

\begin{prop}
	L'ensemble des langages algébrique est clos par substitution algébrique.
\end{prop}

\subsection{Théorème de Chomsky et Schützenberger} % {[}Carton, p. 100-101{]}

Nous avons vu à l'exemple \ref{dyck} que les langages de Dyck sont algébriques. Le théorème de Chomsky et Schützenberger affirme, en un certain sens, que les langages de Dyck contiennent l'essence des langages algébriques.

\begin{defn}[Morphisme alphabétique]
	Un morphisme $\varphi:X^*\to Y^*$ est dit \emph{alphabétique} si pour tout $u\in X^*$, $\abs{\varphi(u)} \le 1$.
\end{defn}

\begin{thm}[Chomsky et Schützenberger]
	Un langage $L$ est algébrique si et seulement si $L=\varphi(D^*_n\cap K)$ pour un entier $n$, un langage rationnel $K$ et un morphisme alphabétique $\varphi$.
\end{thm}

\begin{lem}
	Pour tout $n \ge 0$, il existe un morphisme $\psi:\ A_{n}^{*}\to A_{2}^{*}$ tel que $D_{n}^{*}=\psi^{-1}\left(D_{2}^{*}\right)$.
\end{lem}

\begin{cor}
	Tout langage algébrique s'écrit $\varphi\left(\psi^{-1}\left(D_{2}^{*}\cap K\right)\right)$
	pour des morphismes $\varphi$ et $\psi$ et un langage rationnel
	$K$.
\end{cor}

\begin{rem}
	Une fonction $X\mapsto\varphi\left(\psi^{-1}\left(X\cap K\right)\right)$
	s'appelle une \emph{transduction rationnelle}. Ce sont des transformations
	très naturelles qui peuvent être réalisées avec des automates à deux
	bandes (une pour l'entrée et une pour la sortie).
\end{rem}

%\subsection{X - Théorème de Parikh {[}Carton, p. 86{]}}
%\begin{defn}
%	(Anagrammes)
%\end{defn}
%
%\begin{defn}
%	(Image commutative)\end{defn}
%\begin{thm}
%	(Parikh)
%\end{thm}





\section{Problèmes de décision}

\subsection{Problèmes décidables}

\begin{thm}
	La vacuité d'un langage algébrique (représenté par une grammaire $G$) est décidable en temps $O\left(\abs G\right)$.
\end{thm}

\begin{thm} % {[}Hopcroft, p. 298. La complexité en |G| vient de Wikipedia mais on peut s'en convaincre en lisant l'algo{]}
	L'appartenance d'un mot $u$ à un langage algébrique (représenté par une grammaire) est décidable en temps $O\left(\abs G\abs u^{3}\right)$.
\end{thm}

\begin{rem}
	La forme normale quadratique donne un algorithme exponentiel en $\abs u$ car on peut borner la longueur d'une dérivation et donc tester toutes les dérivations possibles.
\end{rem}

%Floyd, p.321, Earley (descendante)???

%problemes decidables : (L et L' det) L=R, R $\subseteq L$ {[}carton,
%juste pares les trucs indecidables{]}, L rat, L=L' {[}Hopc., p.246{]}


\subsection{Problèmes indécidables}
\begin{prop}[Développement 1, partie 1/2]\label{thindec}
	Les problèmes suivants sont indécidable : % {[}Carton, p. 154{]} {[}DEV, partie 1/2,
	% Admet PCP indécidable{]}
	\begin{itemize}
		\item[1.] Pour deux grammaires, l'intersection des langages engendrés est-elle vide ?
		\item[2.] Pour deux grammaires, les langages engendrés sont-ils égaux ?
		\item[3.] Pour une grammaire, engendre-t-elle le langage de tous les mots sur l'alphabet ?
	\end{itemize}
\end{prop}

Pour prouver the théorème on va utiliser l'indécidabilité du  problème de correspondance de Post (PCP). On commence donc par définir des langages associés à une instance de PCP.

Soit $(u_1,v_1),\dots,(u_m,v_m)$ une instance de PCP sur un alphabet $\Sigma$. On pose $\Sigma' = \Sigma \sqcup A$ où $A=\{a_1,\dots, a_m\}$ et $a_1,\dots,a_m$ sont des lettres n'appartenant pas à $\Sigma$. On définit deux langages sur $\Sigma'$ :
$$L_u=\set{u_{i_1}\dots u_{i_n}a_{i_n}\dots a_{i_1} : n\ge 0\text{ et }1\le i_k \le m}$$
$$L_u'=\set{wa_{i_n}\dots a_{i_1} : n\ge 0, w\in\Sigma^*\text{ et }w\not=u_{i_1}\dots u_{i_n}}$$

On note $\varphi_u(a_{i_n}\dots a_{i_1})$ pour $u_{i_1}\dots u_{i_n}$. On a alors $L_u=\set{\varphi_u(x)x : x \in A^*}$ et $L_u'=\set{wx : x \in A^*\text{ et } w\not=\varphi_u(x)}$.

On remarque que $L_u \sqcup L_u' = \Sigma^*A^*$.

On définit de même $L_v$ et $L_v'$ en remplaçant $u_i$ par $v_i$.

\begin{lem}
	$L_u$ est algébrique.
\end{lem}

\begin{proof}
	La grammaire $G_u = \set{S\to u_1Sa_1+\dots+ u_mSa_m+\varepsilon}$ convient.
\end{proof}

\begin{lem}
	$L_u'$ est algébrique.
\end{lem}

\begin{proof}
	On pose la grammaire $G_u'$ suivante :
	\[\begin{array}{l}
	\displaystyle S\to \sum_{i=1}^mu_iSa_i + \sum_{\substack{1\le i \le m\\x\in\Sigma^*\\ \abs{x}=\abs{u_i}\\x\not=u_i}}xRa_i+\sum\limits_{\substack{1\le i\le m\\x\in\Sigma^*\\\abs{x}<\abs{u_i}}}xTa_i+\sum\limits_{b\in \Sigma}bV\\\\
	\displaystyle R\to \sum_{i=1}^mRa_i+\sum_{b\in\Sigma}bR+\varepsilon\\\\
	\displaystyle T\to \sum_{i=1}^mTa_i+\varepsilon\\\\
	\displaystyle V\to \sum_{b\in\Sigma}bV+\varepsilon
	\end{array}\]
	
	On commence par remarquer que $\L_{G_u'}(R)=\Sigma^*A^*$, $\L_{G_u'}(T)=A^*$ et $\L_{G_u'}(V)=\Sigma^*$.
	
	On montre l'égalité $\L(G_u')= L_u'$ par double inclusion.
	\begin{itemize}
		\item[<<$\subseteq$>>] : Une dérivation commence par$$\displaystyle S\to u_{i_1}Sa_{i_1}\to S\to u_{i_1}u_{i_2}Sa_{i_2}a_{i_1}\to^* u_{i_1}\dots u_{i_j}Sa_{i_j}\dots a_{i_1}$$ et au bout d'un moment, le $S$ disparaît du mot en cours de dérivation. On va noter $\alpha=a_{i_j}\dots a_{i_1}$. On a donc $S\to^*\varphi_u(\alpha)S\alpha$. On a alors trois cas :
		\begin{itemize}
			\item $\varphi_u(\alpha)S\alpha\to \varphi_u(\alpha)xRa_i\alpha\to \varphi_u(\alpha)x\beta\gamma a_i\alpha$ avec $\beta\in \Sigma^*$, $\gamma\in A^*$, $1\le i \le m$, $x\in\Sigma^*$, $\abs{x}=\abs{u_i}$ et $x\not=u_i$. On a donc bien $\varphi_u(\gamma a_i\alpha)=\varphi_u(\alpha)\varphi_u(a_i)\varphi_u(\gamma)=\varphi_u(\alpha)u_i\varphi_u(\gamma)\not=\varphi_u(\alpha)u\beta$.
			\item $\varphi_u(\alpha)S\alpha\to \varphi_u(\alpha)xTa_i\alpha\to \varphi_u(\alpha)x\gamma a_i\alpha$ avec $\gamma\in A^*$, $1\le i \le m$, $x\in\Sigma^*$ et $\abs{x}<\abs{u_i}$. On a donc bien $\varphi_u(\gamma a_i\alpha)=\varphi_u(\alpha)\varphi_u(a_i)\varphi_u(\gamma)=\varphi_u(\alpha)u_i\varphi_u(\gamma)\not=\varphi_u(\alpha)u$.
			\item $\varphi_u(\alpha)S\alpha\to \varphi_u(\alpha)bV\alpha\to \varphi_u(\alpha)b\beta \alpha$ avec $\beta\in \Sigma^*$. On a donc bien $\varphi_u(\alpha)\not=\varphi_u(\alpha)b\beta$.
		\end{itemize}
		\item[<<$\supseteq$>>] : On le prouve par récurrence sur le nombre de symboles de $A$.
		\begin{itemize}
			\item Initialisation : Soit $x\in L_u'\cap\Sigma^*A^0$. On a
			$$S\to x_1V \to x_1x_2V\to \dots \to x_1\dots x_{\abs{x}}V=xV\to x$$
			Donc on a bien $x\in \L(G_u')$.
			\item Récurrence : Supposons que pour tout $x\in L_u'\cap\Sigma^*A^k$, $x\in \L(G_u')$, pour un certain $k\ge 0$. Soit $x \in L_u'\cap\Sigma^*A^{k+1}$. $x=w\alpha a_i$ avec $w\in\Sigma^*$, $\alpha\in A^*$, $a_i\in A$ et $\varphi_u(\alpha a_i)\not= w$. On a donc $u_i\varphi_u(\alpha)\not= w$.
			\begin{itemize}
				\item Si $\abs{w}<\abs{u_i}$, on a $S\to wTa_i\to^* w\alpha a_i=x$. Donc $x\in \L(G_u')$.
				\item Si $\abs{w}\ge \abs{u_i}$, on factorise $w$ en $w=w'w''$ avec $\abs{w'}=\abs{u_i}$. On a donc $u_i\varphi_u(\alpha)\not= w'w''$.
				\begin{itemize}
					\item Si $w'=u_i$, alors $\varphi_u(\alpha)\not=w''$ donc $w''\alpha\in L_u'$. Par hypothèse de récurrence, on a donc $S\to^* w''\alpha$. Donc $S\to u_iSa_i\to^*u_i w''\alpha a_i=w'w''\alpha a_i=w\alpha a_i = x$. Donc $x\in \L(G_u')$.
					\item Si $w'\not= u_i$, $S\to w'Ra_i\to^* w'w''\alpha a_i=w\alpha a_i = x$. Donc $x\in \L(G_u')$.
				\end{itemize}
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{proof}

\begin{lem}
	Une instance de PCP est positive si et seulement si $L_u\cap L_v\not= \emptyset$.
\end{lem}

\begin{proof}
	\begin{itemize}
		\item[<<$\Rightarrow$>>] : Si $u_{i_1}\dots u_{i_n}=v_{i_1}\dots v_{i_n}$ alors $L_u\ni u_{i_1}\dots u_{i_n}a_{i_n}\dots a_{i_1}=v_{i_1}\dots v_{i_n}a_{i_n}\dots a_{i_1}\in L_v$ donc $L_u\cap L_v \not= \emptyset$.
		\item[<<$\Leftarrow$>>] : Si $L_u\cap L_v \not= \emptyset$, soit $x\in L_u\cap L_v$. $x = \varphi_u(\alpha)\alpha$ pour un certain $\alpha \in A^*$ et $x = \varphi_v(\alpha')\alpha'$ pour un certain $\alpha'\in A^*$. Comme $\Sigma$ et $A$ sont disjoints, $\varphi_u(\alpha)=\varphi_v(\alpha')$ et $\alpha=\alpha'$. On en déduit $\varphi_u(\alpha)=\varphi_v(\alpha)$. On factorise $\alpha$ en mots de taille $1$ : $\alpha = a_{i_n}\dots a_{i_1}$. On a alors $u_{i_1}\dots u_{i_n}=\varphi_u(\alpha)=\varphi_v(\alpha)=v_{i_1}\dots v_{i_n}$ donc l'instance de PCP est positive.
	\end{itemize}
\end{proof}

\begin{proof}[Démonstation de \ref{thindec}]
	\item[1'] On pose $1'$ la restriction du problème $1$ aux langages de la forme $L_u$. Par le lemme précédent, le calcul de $L_u$ et $L_v$ (qui peut effectivement se faire) est une réduction de $PCP$ à $1'$. Comme PCP est indécidable, cela implique de $1'$ l'est.
	
	\item[1.] L'inclusion des instance de 1' dans celles de 1 est une réduction de $1'$ vers $1$. Or $1'$ est indécidable donc $1$ l'est également.
	
	\item[3.] TODO
	
	\item[2.] TODO
\end{proof}

\section{Application à la compilation}

\subsection{Arbres de dérivation et ambiguïté} %{[}Carton, p. 90-94{]}

Lors de la compilation, on cherche à donner une structure d'arbre à un programme (c'est-à-dire un mot du langage de programmation). Il est donc naturel de s'assurer que pour chaque mot, un tel arbre est unique. Les langages vérifiant cette propriété sont dits non ambigus.

\begin{defn}[Arbre de dérivation]
	Soit $G=(\Sigma,V,R,S)$ une grammaire algébrique. Un \emph{arbre de dérivation} est un arbre fini dont les noeuds sont étiquettés par $V\sqcup \Sigma \sqcup \set{\varepsilon}$ vérifiant la propriété suivante. Si $X$ est l'étiquette d'un noeud interne et $\alpha_1,\dots,\alpha_n$ sont les étiquettes de ses fils alors $S\to \alpha_1\dots\alpha_n$.
\end{defn}

\begin{defn}[Frontière]
	La \emph{frontière} d'un arbre de dérivation est le mot obtenu par concaténation des étiquettes de ses feuilles de gauche à droite.
\end{defn}

\begin{prop}
	Pour tout non-terminal $X\in V$, le langage $\L_G(X)$ (resp. $\widehat{\L_G(X)}$) est l'ensemble des mots $u\in \Sigma^*$ (resp. $u\in (V\sqcup \Sigma)^*$) tels qu'il existe un arbre de dérivation de racine $X$ et de frontière $u$.
\end{prop}

\begin{example} Les deux arbres suivants sont des arbres de dérivation (de frontière $aaa$) de la grammaire $S\to SS + a$.
	\Tree[.S [.S a ] [.S [.S a ] [.S a ] ] ] \hspace{3em} \Tree[.S [.S [.S a ] [.S a ] ] [.S a ] ]
\end{example}

\begin{defn}[Grammaire ambiguë]
	Une grammaire algébrique $G$ est dite \emph{ambiguë} s'il existe un mot ayant deux arbres de dérivation distincts dont les racines ont la même étiquette.
\end{defn}

\begin{example}
	$S\to SS+a$ est une grammaire algébrique ambiguë.
\end{example}

\begin{rem}
	$S\to aS+a$ est une grammaire algébrique non ambiguë générant le même langage.
\end{rem}

\begin{prop}[Développement 1, partie 2/2]
	L'ambiguïté d'une grammaire algébrique est indécidable.
\end{prop}

\begin{proof}
	TODO
\end{proof}

\begin{defn}[Langage ambigu] %{[}Carton, p. 91{]}
	Un langage algébrique est dit \emph{non ambigu} s'il existe une grammaire algébrique non ambiguë qui l'engendre et \emph{inhéremment ambigu} si toute grammaire algébrique qui l'engendre est ambiguë.
\end{defn}

\begin{prop}
	L'ensemble des langages algébriques non ambigus est clos par union disjointe, par intersection avec un rationnel et par morphisme inverse mais ni par union, ni par morphisme, ni par substitution. % TODO le reste?
\end{prop}

\begin{prop} %  {[}Carton, p. 95{]}
	L'inclusion des langages non ambigus dans les langages algébriques est stricte.
\end{prop}

\subsection{Langages déterministes} % {[}Carton, p. 113{]}

Ne pouvant pas décider l'ambiguïté d'une grammaire algébrique, on cherche une propriété plus forte que l'on sait décider. On étend donc la notion d'automate déterministe aux automates à piles.

\begin{defn}[Automate à pile déterministe]
	Un automate à pile \\$\A=(Q,\Sigma, \Gamma, \Delta, q_0, \gamma_0, F)$ est \emph{déterministe} si pour toute configuration $C$,
	\begin{itemize}
		\item soit il existe une unique transition sortante $C\overset{\varepsilon}{\rightarrowtail}C'$,
		\item soit il n'existe par de transition sortante étiquetée par $\varepsilon$ et pour toute $a\in \Sigma$, il existe au plus une transition sortante de la forme $C\overset{a}{\rightarrowtail}C'$.
	\end{itemize}
\end{defn}

\begin{rem}
	Il n'y a plus équivalence entre les différents modes d'acceptation.
\end{rem}

\begin{defn}[Langage algébrique déterministe(-préfixe)] % {[}Autebert , p. 127{]}
	Un langage algébrique est dit \emph{déterministe} (resp. déterministe préfixe) s'il est accepté par un automate à pile déterministe par état final (resp. par pile vide).
\end{defn}

\begin{prop}
	Tout langage rationnel est algébrique déterministe et l'inclusion est stricte.
\end{prop}

\begin{defn}[Langage préfixe]
	Un langage $L$ est dit \emph{préfixe} si pour tout mot $u\in L$ et tout préfixe strict $v$ de $u$ (c'est-à-dire $u=vw$ et $\abs{v} < \abs{u}$), $v\not\in L$.
\end{defn}

\begin{rem}
	Si $L$ est un langage quelconque et $\$$ n'apparaît pas dans $L$, alors $L\$$ est un langage préfixe.
\end{rem}

\begin{prop} %{[}Autebert, p. 127{]}
	Un langage est déterministe préfixe si et seulement si il est déterministe et préfixe.
\end{prop}

\begin{prop}
	L'ensemble des langages algébriques déterministes est stable par complémentation, intersection avec un rationnel et morphisme inverse, mais ni par union (même disjointe), ni par intersection, ni par morphisme, ni par substitution.
\end{prop}

\begin{prop} % {[}Carton, p.115{]}
	Tout langage algébrique déterministe est non ambigu et l'inclusion est stricte.
\end{prop}

\subsection{Automate des items}

L'automate des items associé à une grammaire algébrique accepte le langage engendré par la grammaire, et peut donc permettre de montrer un sens de l'équivalence \ref{th:equiv}. Il permet également de décrire et motiver les analyseurs LL et LR décrits dans les sous-section suivantes.

Soit une grammaire algébrique $G=\left(\Sigma,\ V,\ R, S\right)$ à
laquelle on ajoute une nouvelle variable $S'$ et une nouvelle règle
$S'\to S$.

\begin{defn}[Item]
À $A\to\alpha\beta\in R$, on associe $\left[A\to\alpha\bullet\beta\right]$
que l'on appelle un \emph{item}. On note $\It$ l'ensemble des items associés
à $G$.
\end{defn}

Intuition : $\left[A\to\alpha\bullet\beta\right]$ représente le fait
que l'on cherche à reconnaître $u\in\Sigma^{*}$ tel que $A\to^{*}\alpha\beta\to^{*}u$.
Par le lemme fondamental, on a donc $v,w\in\Sigma^{*}$ tel que $u=vw$,
$\alpha\to^{*}v$ et $\beta\to^{*}w$. La position de $\bullet$ indique
que l'on a déjà lu $v$ et que l'on veut maintenant lire $w$.
\begin{defn}[Automate des items]
	
	L'automate des items $A_{G}$ associé à $G$ (et $S$) est l'automate
	à pile (généralisé\footnote{On s'autorise à lire plusieurs symboles sur la pile pour faire une transition. On peut émuler ce comportement avec un automate à pile normal qui retient des symboles lus dans ses états.}) à un seul état dont l'alphabet de pile est $\It$,
	qui commence avec une pile contenant $\left[S'\to\bullet S\right]$,
	dont la pile \og acceptrice \fg{} est $\left[S'\to S\bullet\right]$,
	et dont les transitions sont toutes celles de la forme (où l'état
	est omis car l'automate n'a qu'un état) :
	\begin{itemize}
		\item[$(E)$]  \og Expansion \fg{} : $\left[X\to\alpha\bullet B\gamma\right]\overset{\varepsilon}{\rightarrowtail}\left[X\to\alpha\bullet B\gamma\right]\left[B\to\bullet\beta\right]$
		\item[$(L)$]  \og Lecture \fg{} : $\left[X\to\alpha\bullet b\gamma\right]\overset{b}{\rightarrowtail}\left[X\to\alpha b\bullet\gamma\right]$
		\item[$(R)$]  \og Réduction \fg{} : $\left[X\to\alpha\bullet B\gamma\right]\left[B\to\beta\bullet\right]\overset{\varepsilon}{\rightarrowtail}\left[X\to\alpha B\bullet\gamma\right]$ 
	\end{itemize}
\end{defn}

\begin{defn}[Histoire]
	
	L'histoire d'une suite d'items (qui peut apparaître dans la pile)
	$\rho=\left[X_{1}\to\alpha_{1}\bullet\beta_{1}\right]\dots\left[X_{n}\to\alpha_{n}\bullet\beta_{n}\right]$
	est $\hist{\rho}\coloneqq\alpha_{1}\dots\alpha_{n}$ (qui représente
	ce qui a déjà été lu).\end{defn}
\begin{lem}[Développement 2, partie 1/3]
	Si $\left[S'\to\bullet S\right]\transitionn u*\rho$ alors $\hist{\rho}\to^{*}u$.\label{lem:hist}\end{lem}
\begin{proof}
	On le prouve par récurrence sur la longueur du calcul dans l'automate.
	\begin{itemize}
		\item Pour un calcul $\left[S'\to\bullet S\right]\transitionn u0\rho$ de
		longueur $0$, on a $u=\varepsilon$ et $\rho=\left[S'\to\bullet S\right]$
		et donc $\hist{\rho}=\varepsilon\to^{*}\varepsilon=u$.
		\item Pour un calcul $\left[S'\to\bullet S\right]\transitionn u{n+1}\rho$
		de longueur $n+1$, on a $\rho'$ tel que $\left[S'\to\bullet S\right]\transitionn vn\rho'\transitionn w1\rho$
		avec $u=vw$. Par récurrence, $\hist{\rho'}\to^{*}v$. On a trois
		cas suivant si $\rho'\transition w\rho$ est une transition $(E)$,
		$(L)$ ou $(R)$ :
		
		\begin{itemize}
			\item[$(E)$]  $\rho=\rho'\left[B\to\bullet\beta\right]$ et $w=\varepsilon$ donc
			\[
			\hist{\rho}=\hist{\rho'\left[B\to\bullet\beta\right]}=\hist{\rho'}\to^{*}v=u
			\]
			
			\item[$(L)$]  $\rho'=\rho''\left[X\to\alpha\bullet b\gamma\right]$, $\rho=\rho''\left[X\to\alpha b\bullet\gamma\right]$
			et $w=b$ donc
			\[
			\hist{\rho}=\hist{\rho''\left[X\to\alpha b\bullet\gamma\right]}=\hist{\rho''}\alpha b=\hist{\rho'}b\to^{*}vb=u
			\]
			
			\item[$(R)$]  $\rho'=\rho''\left[X\to\alpha\bullet B\gamma\right]\left[B\to\beta\bullet\right]$,
			$\rho=\rho''\left[X\to\alpha B\bullet\gamma\right]$ et $w=\varepsilon$
			donc
			\[
			\hist{\rho''}\alpha\beta=\hist{\rho'}\to^{*}v
			\]
			Or comme $\left[B\to\beta\bullet\right]\in\It$, on a aussi $B\to\beta\in R$.
			D'où
			\[
			\hist{\rho}=\hist{\rho''}\alpha B\to\hist{\rho''}\alpha\beta\to^{*}v=u
			\]
			
		\end{itemize}
	\end{itemize}
\end{proof}
\begin{lem}[Développement 2, partie 2/3]
	Pour tout $n\ge1$, $A\in V$ et $u\in\Sigma^{*}$, si $A\to^{n}u$
	alors il existe $A\to\alpha\in R$ tel que $\left[A\to\bullet\alpha\right]\transitionn u*\left[A\to\alpha\bullet\right]$.\label{lem:regle}\end{lem}
\begin{proof}
	On le prouve par récurrence forte sur $n$.\end{proof}
\begin{itemize}
	\item Pour une dérivation de longueur $1$, $A\to^{1}u$ donc $A\to u\in R$.
	On en déduit (en notant $a_{1},\ \dots,\ a_{k}$ les lettres de $u$)
	\[
	\left[A\to\bullet u\right]=\left[A\to\bullet a_{1}a_{2}\dots a_{k}\right]\underset{(L)}{\transition{a_{1}}}\left[A\to a_{1}\bullet a_{2}\dots a_{k}\right]\underset{(L)}{\transition{a_{2}}}\dots\underset{(L)}{\transition{a_{k}}}\left[A\to a_{1}a_{2}\dots a_{k}\bullet\right]=\left[A\to u\bullet\right]
	\]
	Et donc $\left[A\to\bullet u\right]\transitionn u*\left[A\to u\bullet\right]$.
	\item Pour une dérivation de longueur $n+1$, on a $A\to^{1}\alpha\to^{n}u$.
	On note $\alpha_{1},\ \dots,\ \alpha_{k}$ les lettres de $\alpha$.
	Par le lemme fondamental, on a $u_{1},\ \dots,\ u_{k}\in\Sigma^{*}$
	tel que pour chaque $i\in\intint 1k$, $\alpha_{i}\to^{n_{i}}u_{i}$
	avec ${\displaystyle \sum_{i=1}^{k}}n_{i}=n$. En particulier, pour
	chaque $i\in\intint 1k$, $n_{i}\le n$. Pour chaque $i\in\intint 1k$,
	il y a deux cas :
	
	\begin{itemize}
		\item $\alpha_{i}\in\Sigma$ et alors $\left[A\to\alpha_{1}\dots\alpha_{i-1}\bullet\alpha_{i}\alpha_{i+1}\dots\alpha_{k}\right]\underset{(L)}{\transition{\alpha_{i}}}\left[A\to\alpha_{1}\dots\alpha_{i-1}\alpha_{i}\bullet\alpha_{i+1}\dots\alpha_{k}\right]$
		\item $\alpha_{i}\in V$ et alors, par récurrence, on a $\alpha_{i}\to\beta\in P$
		tel que $\left[\alpha_{i}\to\bullet\beta\right]\transitionn{u_{i}}*\left[\alpha_{i}\to\beta\bullet\right]$.
		On a donc
		\begin{align*}
		\left[A\to\alpha_{1}\dots\alpha_{i-1}\bullet\alpha_{i}\alpha_{i+1}\dots\alpha_{k}\right]\underset{(E)}{\transition{\varepsilon}}\left[A\to\alpha_{1}\dots\alpha_{i-1}\bullet\alpha_{i}\alpha_{i+1}\dots\alpha_{k}\right]\left[\alpha_{i}\to\bullet\beta\right]\\
		\transitionn{u_{i}}*\left[A\to\alpha_{1}\dots\alpha_{i-1}\bullet\alpha_{i}\alpha_{i+1}\dots\alpha_{k}\right]\left[\alpha_{i}\to\beta\bullet\right]\underset{(R)}{\transition{\varepsilon}}\left[A\to\alpha_{1}\dots\alpha_{i-1}\alpha_{i}\bullet\alpha_{i+1}\dots\alpha_{k}\right]
		\end{align*}
		En combinant les exécutions on obtient
		\[
		\left[A\to\bullet\alpha_{1}\alpha_{2}\dots\alpha_{k}\right]\transitionn{u_{1}}*\left[A\to\alpha_{1}\bullet\alpha_{2}\dots\alpha_{k}\right]\transitionn{u_{2}}*\dots\transitionn{u_{n}}*\left[A\to\alpha_{1}\alpha_{2}\dots\alpha_{k}\bullet\right]
		\]
		\\
		Et donc on a bien $\left[A\to\bullet\alpha\right]\transitionn u*\left[A\to\alpha\bullet\right]$,
		c'est-à-dire $A\to\alpha\in R$ convient.
	\end{itemize}
\end{itemize}
\begin{thm}[Développement 2, partie 3/3]
	$\L\left(A_{G}\right)=\L\left(G\right)$
\end{thm}
\begin{proof}
	On prouve les deux inclusions.
	\begin{itemize}
		\item[\og $\subseteq$ \fg{}]  Soit $u\in\L\left(A_{G}\right)$. Par définition de $\L\left(A_{G}\right)$,
		$\left[S'\to\bullet S\right]\transitionn u0\left[S'\to S\bullet\right]$.
		Par le lemme \ref{lem:hist}, on a donc $S=\hist{\left[S'\to S\bullet\right]}\to^{*}u$,
		c'est-à-dire $u\in\L\left(G\right)$.
		\item[\og $\supseteq$ \fg{}]  Soit $u\in\L\left(G\right)$. Par définition de $\L\left(G\right)$,
		on a $S'\to^{*}u$. Par le lemme \ref{lem:regle}, on a donc $S'\to\alpha\in P$
		tel que $\left[S'\to\bullet\alpha\right]\transitionn u*\left[S'\to\alpha\bullet\right]$.
		Or la seule règle de la forme $S'\to\alpha$ est $S'\to S$. On a
		donc $\left[S'\to\bullet S\right]\transitionn u*\left[S'\to S\bullet\right]$,
		c'est-à-dire $u\in\L\left(A_{G}\right)$.
	\end{itemize}
\end{proof}

\subsection{LL(k) (TODO)}

\subsection{LR(k) (TODO)}

refs

Reinhard Wilhelm, Dieter Maurer, Compiler design, p. 281-282

\end{document}